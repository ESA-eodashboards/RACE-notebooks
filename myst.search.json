{"version":"1","records":[{"hierarchy":{"lvl1":"Example Viewer Template"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Example Viewer Template"},"content":"This template repository is intended to allow easy instantiation of an example viewer for jupyterlab notebooks.\nExternal repositories can be added via git submodules to the external_notebooks folder.\nThe github action will traverse available notebooks and try to extract metadata information as well as build them with Jupyterbook (v2 and MYST).\nThe build package is then deployed on github pages.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"type":"lvl1","url":"/notebooks/detect-trucks-sentinel2","position":0},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2","position":1},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"type":"lvl1","url":"/notebooks/detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data","position":2},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"content":"","type":"content","url":"/notebooks/detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data","position":3},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Parallax-based truck detection"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#parallax-based-truck-detection","position":4},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Parallax-based truck detection"},"content":"\n\nThis notebook is a comprehensive script for detecting trucks with Sentinel-2 data. In order to run the detection in your area of interest you will have to modify two cells:\n\nArea of Interest (specify the aoi as bounding box)\n\nDate (specify an acquisition date)\n\nAfterwards, you may simply run all cells and check the result at the end of the script where you can also write the detections as points.\n\nEnsure that you have access to the Sentinel Hub resources for retrieving Sentinel-2 data through its API (via xcube_sh).\n\nAuthor: Henrik Fisser, 2020Explanations on the truck detection on GitHub: \n\nhttps://​github​.com​/hfisser​/Truck​_Detection​_Sentinel2​_COVID19\n\nimport os\nimport subprocess\nimport sys\n\n# installations\ndef install_package(pkg):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\ninstall_package(\"OSMPythonTools\")\ninstall_package(\"geocube\")\n\n# OSM API\nfrom OSMPythonTools.overpass import overpassQueryBuilder, Overpass\n\nimport numpy as np\nimport xarray as xr\nimport geocube\nimport geopandas as gpd\nimport pandas as pd\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube.core.maskset import MaskSet\nfrom rasterio import features\nfrom affine import Affine\nfrom shapely import geometry, coords\nfrom shapely.geometry import Polygon, Point, box\nfrom numba import jit\n\nimport IPython.display\n%matplotlib inline\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#parallax-based-truck-detection","position":5},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Area of Interest"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#area-of-interest","position":6},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Area of Interest"},"content":"Specify an area of interest as bounding box in format:xmin, ymin, ymax, ymax\n\nbbox = -3.85, 40.3, -3.55, 40.5 # Madrid\nIPython.display.GeoJSON(box(*bbox).__geo_interface__)\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#area-of-interest","position":7},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Date"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#date","position":8},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Date"},"content":"Select a cloud-free acquisition and provide the date as “YYYY-MM-DD”.\nYou may select data e.g. here:Copernicus Open Access Hub\n\n\nhttps://​scihub​.copernicus​.eu​/dhus​/​#​/home EO Browser\n\n\nhttps://​apps​.sentinel​-hub​.com​/eo​-browser​/​?zoom​=​10​&​lat​=​41​.9​&​lng​=​12​.5​&​themeId​=​DEFAULT​-THEME\n\ndate_start = \"2020-05-18\"\ndate_end = \"2020-05-19\"\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#date","position":9},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Open Street Maps (OSM)"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#open-street-maps-osm","position":10},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Open Street Maps (OSM)"},"content":"Trucks are only detected on roads obtained from OSM.\nYou may specify road types to include. Their descriptions can be found here:\n\nhttps://​wiki​.openstreetmap​.org​/wiki​/Key:highway\n\nosm_values = [\"motorway\", \"trunk\", \"primary\"] # all of key \"highway\"\nroads_buffer = 0.00022 # degree, OSM road vectors are buffered, for motorway, the others lower\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#open-street-maps-osm","position":11},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Processing methods"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#processing-methods","position":12},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Processing methods"},"content":"In the following cells all needed methods are defined. They will be invoked further below.\n\n# re-order bbox from W,S,E,N to S,W,N,E\ndef convert_bbox_osm(bbox):\n    offset = 0.05 # add a buffer to bbox in order to be sure cube is entirely covered\n    bbox_osm = [bbox[1], bbox[0], bbox[3], bbox[2]]\n    bbox_osm[0] -= offset # min lat\n    bbox_osm[1] -= offset # min lon\n    bbox_osm[2] += offset # max lat\n    bbox_osm[3] += offset # max lon\n    return bbox_osm\n\n# bbox List of four coords\n# osm_value String OSM value\n# osm_key String OSM key\n# element_type List of String\n# returns GeoDataFrame\ndef get_osm(bbox, \n            osm_value,\n            element_type = [\"way\", \"relation\"]):\n    osm_key = \"highway\"\n    bbox_osm = convert_bbox_osm(bbox)\n    quot = '\"'\n    select = quot+osm_key+quot + '=' + quot+osm_value+quot\n    select_link = select.replace(osm_value, osm_value + \"_link\") # also get road links\n    select_junction = select.replace(osm_value, osm_value + \"_junction\")\n    geoms = []\n    for selector in [select, select_link, select_junction]:  \n        try:\n            query = overpassQueryBuilder(bbox=bbox_osm, \n                                         elementType=element_type, \n                                         selector=selector, \n                                         out='body',\n                                         includeGeometry=True)\n            elements = Overpass().query(query, timeout=60).elements()\n            # create multiline of all elements\n            if len(elements) > 0:\n                for i in range(len(elements)):\n                    elem = elements[i]\n                    geoms.append(elem.geometry())\n        except:\n            Warning(\"Could not retrieve \" + select)\n    try:\n        lines = gpd.GeoDataFrame(crs = \"EPSG:4326\", geometry = geoms)\n        n = len(geoms)\n        lines[\"osm_value\"] = [osm_value]*n # add road type\n        return lines\n    except:\n        Warning(\"Could not merge \" + osm_value)\n        \n# buffer Float road buffer distance [m]\n# bbox List of four coords\n# bbox_id Integer processing id of bbox\n# osm_values List of String OSM values\n# osm_key String OSM key\n# roads_buffer Float buffer width\n# returns GeoDataFrame\ndef get_roads(bbox, osm_values, roads_buffer):\n    osm_key = \"highway\"\n    roads = []\n    has_error = []\n    offset = 0.00002\n    buffer_dist = \"buffer_distance\"\n    # buffer according to road type\n    m,t,p,s,ter = \"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\"\n    buffers = {m:roads_buffer, t:roads_buffer-offset, p:roads_buffer-(2*offset), s:roads_buffer-(3*offset), ter:roads_buffer-(4*offset)}\n    osm_values_int = {m:1, t:2, p:3, s:4, ter:5}\n    for osm_value in osm_values:\n        roads_osm = get_osm(bbox, osm_value)\n        try:\n            roads_osm = get_osm(bbox, osm_value)\n            roads_osm[buffer_dist] = [buffers[osm_value]] * len(roads_osm)\n            roads_osm[\"osm_value_int\"] = osm_values_int[osm_value]\n            roads.append(roads_osm)\n        except:\n            has_error.append(1)\n            print(\"'get_osm'\" + \"failed for bbox_id osm_value \" + osm_value + \"osm_key\" + osm_key)\n    if len(roads) > len(has_error):\n        roads_merge = gpd.GeoDataFrame(pd.concat(roads, ignore_index=True), crs=roads[0].crs)\n        buffered = roads_merge.buffer(distance=roads_merge[buffer_dist])\n        roads_merge.geometry = buffered\n        return roads_merge\n\n# osm geodataframe of polygons\n# reference_raster xarray with lat and lon\n# returns numpy array\ndef rasterize_osm(osm, reference_raster):\n    osm_values = list(set(osm[\"osm_value\"]))\n    nan_placeholder = 100\n    road_rasters = []\n    for osm_value in osm_values:\n        osm_subset = osm[osm[\"osm_value\"] == osm_value]\n        raster = rasterize(osm_subset, reference_raster.lat, reference_raster.lon)\n        cond = np.isfinite(raster)\n        raster_osm = np.where(cond, list(osm_subset.osm_value_int)[0], nan_placeholder) # use placeholder instead of nan first\n        raster_osm = raster_osm.astype(np.float)\n        road_rasters.append(raster_osm)        \n    # merge road types in one layer\n    road_raster_np = np.array(road_rasters).min(axis=0) # now use the lowest value (highest road level) because some intersect\n    road_raster_np[road_raster_np == nan_placeholder] = 0\n    return road_raster_np # 0=no_road 1=motorway, 2=trunk, ...\n\ndef transform_lat_lon(lat, lon):\n    lat = np.asarray(lat)\n    lon = np.asarray(lon)\n    trans = Affine.translation(lon[0], lat[0])\n    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n    return trans * scale\n\ndef rasterize(polygons, lat, lon, fill=np.nan):\n    transform = transform_lat_lon(lat, lon)\n    out_shape = (len(lat), len(lon))\n    raster = features.rasterize(polygons.geometry, out_shape=out_shape,\n                                fill=fill, transform=transform,\n                                dtype=float)\n    return xr.DataArray(raster, coords={\"lat\":lat, \"lon\":lon}, dims=(\"lat\", \"lon\"))\n\n# TruckDetector detects trucks at acquisition-level\nclass TruckDetector():   \n    def __init__(self, band_stack):\n        is_none = band_stack is None\n        self.band_stack = band_stack.chunk(band_stack.dims[\"lat\"], band_stack.dims[\"lon\"]) if not is_none else None\n        self.no_truck_mask = None\n        self.trucks = None\n    \n    def detect(self):\n        B02 = self.band_stack.B02.persist().values\n        B03 = self.band_stack.B03.persist().values\n        B04 = self.band_stack.B04.persist().values\n        B08 = self.band_stack.B08.persist().values\n        B11 = self.band_stack.B11.persist().values\n        no_truck_mask = calc_no_trucks(B02, B03, B04, B08, B11)\n        trucks = detect_trucks(B02, B03, B04, no_truck_mask)\n        lon_lat = {\"lat\":self.band_stack.lat, \"lon\":self.band_stack.lon}\n        self.no_truck_mask = xr.DataArray(no_truck_mask, coords=lon_lat, dims=(\"lat\", \"lon\"))\n        self.trucks = xr.DataArray(trucks, coords=lon_lat, dims=(\"lat\", \"lon\")).astype(np.int)\n        self.filter_trucks()\n                            \n    def filter_trucks(self):\n        self.trucks = filter_spatial_3x3_extended(self.trucks)\n        \n# take xarray and ensure each value with 1 in data has no neighbor with 1 in an extended 3x3 block. Extended means: horizontally and vertically\n# it is also checked for the second-next pixel\n# Method checks only surrounding of values equal 1\n# arr xarray DataArray with values and lat lon\ndef filter_spatial_3x3_extended(arr):\n    values = arr.values\n    lon = arr.lon\n    lat = arr.lat\n    valid = np.where(arr == 1)\n    for y,x in zip(valid[0], valid[1]):\n        y_above = y - 1\n        y_above_next = y - 2\n        x_left = x - 1\n        x_right = x + 1\n        x_left_next = x - 2\n        space_left = x_left >= 0\n        space_right = x_right >= 0 and x_right < len(lon)\n        space_above = y_above >= 0\n        val_left_above = values[y_above, x_left] if space_left and space_above else 0\n        val_right_above = values[y_above, x_right] if space_right and space_above else 0\n        val_left = values[y, x_left] if space_left else 0\n        val_above = values[y_above, x] if space_above else 0\n        val_left_next = values[y, x_left_next] if x_left_next >= 0 else 0\n        val_above_next = values[y_above_next, x] if y_above_next >= 0 else 0\n        # if any of the values left, above and left above has 1 set current value 0\n        if (val_left_above + val_right_above + val_left + val_above + val_left_next + val_above_next) >= 1:\n            values[y,x] = 0\n    arr.values = values\n    return arr\n\n# extracts coordinates at value in np array and returns points as GeoDataFrame\n# data 2d np array\n# match_value Float value in data where point coordinates are extracted\n# lon_lat dict of:\n### \"lon\": np array longitude values\"\n### \"lat\": np array latitude values\"\n# crs String EPSG:XXXX\ndef points_from_np(data, match_value, lon_lat, crs):\n    indices = np.argwhere(data == match_value)\n    if len(indices) > 0:\n        lat_indices = indices[:,[0]]\n        lon_indices = indices[:,[1]]\n        lat_coords = lon_lat[\"lat\"][lat_indices]\n        lon_coords = lon_lat[\"lon\"][lon_indices]\n        points = gpd.GeoDataFrame(geometry = gpd.points_from_xy(lon_coords, lat_coords))\n        points.crs = crs\n        return points\n    \ndef raster_to_points(raster, lon_lat, field_name, crs):\n    points_list = []\n    match_values = np.unique(raster[(raster != 0) * ~np.isnan(raster)]) # by pixel value\n    for x in match_values:\n        points = points_from_np(raster, x, lon_lat, crs=crs)\n        points[field_name] = [x] * len(points)\n        points_list.append(points)\n    return gpd.GeoDataFrame(pd.concat(points_list, ignore_index=True))\n        \n# Calculate a binary mask where pixels that are definitely no trucks are represented as 0.\n# thresholds Dict with at least:\n### max_ndvi Float above this val: no trucks. For Vegetation\n### max_ndwi Float above this val: no trucks. For Water\n### max_ndsi Float above this val: no_trucks. For Snow\n### min_rgb Float above this val: no_trucks. For dark surfaces, e.g. shadows\n### max_blue Float above this val: no_trucks\n### max_green Float above this val: no trucks\n### max_red Float above this val: no trucks\n### min_b11 Float below this val: no trucks. For dark surfaces, e.g. shadows\n### max_b11 Float below this val: no trucks. For bright (sealed) surfaces, e.g. buildings\n@jit(nopython=True, parallel=True)\ndef calc_no_trucks(B02, B03, B04, B08, B11):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    ndvi_mask = ratio(B08, B04) < th[\"max_ndvi\"]\n    ndwi_mask = ratio(B02, B11) < th[\"max_ndwi\"]\n    ndsi_mask = ratio(B03, B11) < th[\"max_ndsi\"]\n    low_rgb_mask = (B02 > th[\"min_blue\"]) * (B03 > th[\"min_green\"]) * (B04 > th[\"min_red\"])\n    high_rgb_mask = (B02 < th[\"max_blue\"]) * (B03 < th[\"max_green\"]) * (B04 < th[\"max_red\"])\n    no_truck_mask = ndvi_mask * ndwi_mask * ndsi_mask * low_rgb_mask * high_rgb_mask\n    return no_truck_mask\n\n# Calculate a binary mask where trucks are represented as 1 and no trucks as 0.\n# thresholds Dict with at least:\n### min_green_ratio Float, minimum value of blue-green ratio\n### min_red_ratio Float, minimum value of blue-red ratio\n@jit(nopython=True, parallel=True)\ndef detect_trucks(B02, B03, B04, no_truck_mask):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    bg_ratio = ratio(B02, B03)\n    br_ratio = ratio(B02, B04)\n    bg = bg_ratio > th[\"min_blue_green_ratio\"]\n    br = br_ratio > th[\"min_blue_red_ratio\"]\n    bg_max = bg_ratio < th[\"max_blue_green_ratio\"]\n    br_max = br_ratio < th[\"max_blue_red_ratio\"]\n    trucks = (bg * br * bg_max * br_max) * no_truck_mask\n    return trucks\n\n@jit(nopython=True, parallel=True)\ndef ratio(a, b):\n    return (a-b)/(a+b)\n\n# AcquisitionProcessor processes all valid pixels of a single acquisition in cube\nclass AcquisitionProcessor():\n    def __init__(self, date_np64, cube):\n        self.date_np64 = date_np64\n        self.cube = cube\n        self.band_stack = cube.sel(time = date_np64)\n        self.detector = None\n        self.no_clouds = None\n        self.osm_mask = None\n           \n    def mask_clouds(self):\n        cloud_masking_thresholds = {\"rgb\":0.25,\"blue_green\":0.2,\"blue_red\":0.2}\n        scl = MaskSet(self.band_stack.SCL)\n        high_prob = scl.clouds_high_probability\n        med_prob = scl.clouds_medium_probability\n        cirrus = scl.cirrus\n        no_data = scl.no_data\n        rgb_cloud_mask = calc_rgb_cloud_mask(self.band_stack, cloud_masking_thresholds)\n        self.no_clouds = (high_prob + med_prob + cirrus + no_data + rgb_cloud_mask) == 0\n        self.band_stack = self.band_stack.where(self.no_clouds)\n    \n    def mask_with_osm(self, osm_mask):\n        self.osm_mask = osm_mask\n        self.band_stack = self.band_stack.where(self.osm_mask != 0)\n                \n    def do_detection(self):\n        self.detector = TruckDetector(self.band_stack)\n        self.detector.detect()\n        \ndef calc_rgb_cloud_mask(band_stack, cloud_masking_thresholds):\n    B02, B03, B04 = band_stack.B02, band_stack.B03, band_stack.B04\n    c = cloud_masking_thresholds[\"rgb\"]\n    clouds_rgb = ((B02 > c) + (B03 > c) + (B04 > c)) >= 1\n    # attempt to mask haze without masking out truck pixels (similar! higher blue than red and green)\n    blue_green_ratio = (B02-B03) / (B02+B03)\n    blue_red_ratio = (B02-B04) / (B02+B04)\n    clouds_blue_green = blue_green_ratio > cloud_masking_thresholds[\"blue_green\"]\n    clouds_blue_red = blue_red_ratio > cloud_masking_thresholds[\"blue_red\"]\n    clouds = (clouds_rgb + clouds_blue_green + clouds_blue_red) >= 1\n    return clouds\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#processing-methods","position":13},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":14},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nconfig = CubeConfig(dataset_name = \"S2L2A\",\n                    band_names = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"SCL\"],\n                    tile_size = [512, 512],\n                    geometry = bbox,\n                    spatial_res = 0.00009,\n                    time_range = [date_start, date_end])\ncube = open_cube(config)\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":15},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/notebooks/detect-trucks-sentinel2#acquisition","position":16},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nacquisition = AcquisitionProcessor(cube.time.values[0], cube)\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#acquisition","position":17},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/notebooks/detect-trucks-sentinel2#plot-rgb","position":18},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nrgb_bands = [\"B04\", \"B03\", \"B02\"]\ncoords, dims = [rgb_bands, cube.lat, cube.lon], [\"bands\", \"lat\", \"lon\"]\nrgb = np.vstack([cube.B04.persist().values, cube.B03.persist().values, cube.B02.persist().values])\nrgb_xr = xr.DataArray(rgb, coords=coords, dims=dims)\nrgb_xr.plot.imshow(figsize=[12,10], rgb=\"bands\", vmin=0, vmax=0.4)\nrgb, rgb_xr = None, None\n\nRGB reflectance\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#plot-rgb","position":19},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get OSM roads"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#get-osm-roads","position":20},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get OSM roads"},"content":"\n\nosm_roads = get_roads(bbox, osm_values, roads_buffer)\nosm_roads.plot(figsize=[12,10])\n\nThe OSM road vectors are buffered, hence we see polygons here.\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#get-osm-roads","position":21},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"type":"lvl3","url":"/notebooks/detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":22},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"content":"\n\nosm_roads_np = rasterize_osm(osm_roads, cube.B02)\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":23},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Mask"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#mask","position":24},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Mask"},"content":"In case there are clouds in the imagery, they are masked out here. Furthermore, the data is constrained to the OSM roads.\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#mask","position":25},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Clouds","lvl2":"Mask"},"type":"lvl3","url":"/notebooks/detect-trucks-sentinel2#clouds","position":26},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Clouds","lvl2":"Mask"},"content":"\n\nacquisition.mask_clouds()\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#clouds","position":27},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"To OSM roads","lvl2":"Mask"},"type":"lvl3","url":"/notebooks/detect-trucks-sentinel2#to-osm-roads","position":28},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"To OSM roads","lvl2":"Mask"},"content":"Only pixels within the buffered OSM roads are considered.\n\nacquisition.mask_with_osm(osm_roads_np)\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#to-osm-roads","position":29},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Detect trucks"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#detect-trucks","position":30},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Detect trucks"},"content":"This is the actual detection being invoked in the “do_detection” wrapper. The output is an xarray DataArray, which is afterwards converted to a GeoDataFrame of points.\n\nacquisition.do_detection()\n# raster detections to points\ntruck_points = raster_to_points(acquisition.detector.trucks.values, {\"lon\":cube.lon.values, \"lat\":cube.lat.values}, \"trucks\", \"EPSG:4326\")\ntruck_points.plot(figsize=[12,10])\n\n","type":"content","url":"/notebooks/detect-trucks-sentinel2#detect-trucks","position":31},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Write detections"},"type":"lvl2","url":"/notebooks/detect-trucks-sentinel2#write-detections","position":32},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Write detections"},"content":"If you would like to write the truck points, simply modify the file path here\n\ntruck_points.to_file(\"trucks.gpkg\", driver=\"GPKG\")","type":"content","url":"/notebooks/detect-trucks-sentinel2#write-detections","position":33},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"type":"lvl1","url":"/notebooks/fire-impact-analysis","position":0},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"content":"","type":"content","url":"/notebooks/fire-impact-analysis","position":1},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":2},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"content":"\n\nThis notebook demonstates how to access and analyse data found on the \n\nRapid Action for Citizens with Earth Observation (RACE) and \n\nEarth Observation Dashboard. It uses the EC-JRC’s Global Human Settlement (GHS) Layer which contains global data about the total built-up surface from 1975 to 2030 and was derived from Sentinel2 composite and Landsat imagery. The data is openly available and can be downloaded \n\nhere. It was ingested in EDC and provided as a layer, check out the documentation \n\nhere for further information about the data properties in EDC.\nThe GHS indicator can be explored on the EO Dashboard by selecting the \n\nEXPLORE DATASETS mode.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":3},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":4},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"content":"\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":5},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":6},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"content":"Access to EO archives from main all open missions (e.g. Sentinel, Landsat, MODIS, etc.), commercial satellites (PlanetScope, Pleiades, SPOT, WorldView, etc.) as well as Level 3 products (Copernicus Land Monitoring Services, C3S, etc.)\n\nAnalyse, compare and correlate EO data through Xcube and operational tools (Sentinel Hub)\n\nManage different data formats and type in a transparent way (raster, vector, COGs, Zarr, etc.)\n\nBring and store your own data and algorithm for real-time and batch processing operations\n\nComputational resources and storage to run Jupyter Notebooks and your deployed Applications within your Kubernetes-powered workspace\n\nExpose your apps on the EDC marketplace to third-parties and provide easy access to your managed API service to customers\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":7},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-market-place","position":8},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"content":"\n\nData Products: e.g. \n\nSentinel Hub\n\nPlatform Services: e.g. \n\nEOxHub\n\nAPI Services: e.g. \n\nGeoDB, \n\nSH-Statistical API\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-market-place","position":9},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":10},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"content":"Visualizing wildfire events with Sentinel-2 imagery\n\nQuerying data via Statistical API for the chosen Area of Interest\n\nTransforming the output of the API request into a geoJSON polygon that contains the extent of the built up area in the AOI\n\nAccessing Sentinel-5p Carbon monoxide data from SentinelHub\n\nDisplaying the time series of the CO concentration over the populated area to evaluate the possible impact of the fire emissions\n\nThis notebook runs with the python environment users-edc-2023.07-01 and was prepared by Leah Sturm (University of Trier, Germany).\n\n#import necessary libraries\nimport os\nimport numpy as np\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import shapes\nimport requests\nimport geojson\nfrom shapely.geometry import shape\nfrom rasterio.transform import from_origin\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n\n# Sentinel Hub requirements\nfrom sentinelhub import (SHConfig, DataCollection, Geometry, BBox, Geometry,\n                         SentinelHubRequest, filter_times, bbox_to_dimensions, MimeType, \n                         SentinelHubBYOC, ByocCollection, ByocTile, ByocCollectionAdditionalData,\n                         DownloadFailedException, CRS, SentinelHubStatistical)\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nclient_id = os.environ[\"SH_CLIENT_ID\"]\nclient_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n\n# config\n\n","type":"content","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":11},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":12},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"content":"\n\n# Get the current date and format it as a string\ncurrent_date = datetime.now().strftime(\"%Y-%m-%d\")\n\n# Define the folder name and path\nfolder_name = f\"folder_{current_date}\"\nfolder_path = os.path.join(os.getcwd(), folder_name)\n\n# Check if the folder already exists, and create it if not\nif not os.path.exists(folder_path):\n    os.mkdir(folder_path)\n    print(f\"Folder '{folder_name}' created at: {folder_path}\")\nelse:\n    print(f\"Folder '{folder_name}' already exists at: {folder_path}\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":13},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":14},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"content":"The wildfire season during the summer of 2022 in Europe was exceptional, marked by a high number of observed fires, a large extent of burned area, and remarkably high atmospheric emissions linked to these fires. According to data from the European Forest Fire Information System (EFFIS), fires were reported in 26 out of the 27 European countries, collectively burning 837,212 hectares. A significant portion of these wildfires happened in July, with Spain, Portugal, France, and Italy experiencing the most damages.\n\nThe selected wildfire incident for this notebook occurred in the Gironde region of southwestern France, near the city of Bordeaux, in 2022. The significant fire event started on July 17, 2022, lasted for two weeks while burning approximately 7,000 hectares of land. Notably, the Copernicus Atmosphere Monitoring Service (CAMS) recorded exceptionally elevated levels of carbon monoxide emissions throughout the duration of this event.\n\nRelated articles about the event and the wildfire occurrence in 2022:\n\nEuropean Space Agency\n\nEU ScienceHub\n\nEFFIS\n\nCopernicus Atmosphere Monitoring Service\n\nEUMETSAT\n\n","type":"content","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":15},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":16},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"In this first part we are going to visualize the fire event to get an overview of the location and the occuring emissions. In the following cells we will access Sentinel-2 imagery from \n\nSentinel Hub. Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds. The following cells to access Sentinel-2 data are based on the example notebook “Australian Bushfires” which is available in the \n\nEuro Data Cube Marketplace.\n\nTo get a first overview of the fire event we are going to look at the true colour image captured on the day of the start of the fire.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":17},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":18},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\nbbox_coords =[\n  -1.006524,\n  44.318762,\n  -0.406214,\n  44.586411\n]\n\nresolution = 20\nArea_of_interest_bbox = BBox(bbox=bbox_coords, crs=CRS.WGS84)\nArea_of_interest_size = bbox_to_dimensions(Area_of_interest_bbox, resolution=resolution)\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Utilities\nimport IPython.display\nfrom IPython.display import display, GeoJSON\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox_coords,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":19},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":20},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"We build the request according to the \n\nAPI Reference, using the SentinelHubRequest class. Each Process API request also needs an \n\nevalscript.\n\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\n\na list of input data collections with time interval,\n\na format of the response,\n\na bounding box and it’s size (size or resolution).\n\nThe evalscript is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\n\n# define the evalscript \n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\n# we nned to specify the collection and the time interval\n# for a list of collections available in the Sentinel Hub visit https://docs.sentinel-hub.com/api/latest/data/ \n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A, \n            time_interval=('2022-07-16', '2022-07-18'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=Area_of_interest_bbox,\n    size=Area_of_interest_size,\n    config=config\n)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":21},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":22},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# send the request to Sentinel Hub\n#true_color_imgs = request_true_color.get_data()\n\nmax_retries = 3\nretry_count = 0\nwhile retry_count < max_retries:\n    try:\n        true_color_imgs = request_true_color.get_data()\n        break  # Image displayed successfully, exit the loop\n    except Exception as e:\n        print(f\"Failed to display image: {e}\")\n        retry_count += 1\n        if retry_count < max_retries:\n            print(f\"Retrying (Attempt {retry_count})...\")\n \nif retry_count >= max_retries:\n    print(\"Maximum retries reached. Unable to retrieve the image.\")\n    \n# Define the plot_image function\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nimage = true_color_imgs[0]\nprint(f'Image type: {image.dtype}')\n    \n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\n\n# Maximum number of retry attempts\n\nplot_image(image, factor=3.5/255, clip_range=(0,1))\n\nThe visualized image captures the start of the  wildfire event which is prominently visible in the top right corner. The plume and emissions from the fire event extend westwards. Consequently, the analysis within this notebook will center around urban areas within those western regions.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":23},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":24},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# define the coordinates\ntop_left_x =  -1.26747\ntop_left_y = 44.674299\nbottom_right_x = -0.962647\nbottom_right_y = 44.508045\n\nbbox = [   \n  top_left_x,\n  bottom_right_y,\n  bottom_right_x,\n  top_left_y\n        ]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":25},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":26},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# Check the resolution and pixels constrains (they have to be maximal 2500x2500)\nresolution = 10\naoi = BBox(bbox=bbox, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi, resolution=resolution)\n\n# These values are needed to set the right dimensions for saving the request as tiff file later\nwidth = aoi_size[0]  \nheight = aoi_size[1] \n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":27},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":28},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The \n\nStatistical API empowers users to derive insightful statistics from satellite imagery, eliminating the need to download large image files. When making a Statistical API request,it is possible to define an AOI, time frame, evalscript, and the specific statistical measures you wish to compute. The resulting statistics are conveniently included in the API response. With the Statistical API, the user can compute statistics such as cloud pixel percentages within a defined area and timeframe or calculate metrics like mean, standard deviation, and histogram of band values for a specific parcel over a given time frame.\n\nTo access the population density layer, we need to use the designated BYOC ID: 0c7aa265-50f9-4947-9980-2ee5ae204803 found on EDC. To query the GHS layer effectively, we need to provide the BYOC ID, the coordinates from the created GeoJSON file as AOI, the desired timeframe, and the necessary user credentials as inputs. The GHS layer contains data from 1975 to 2030 in 5 years intervals. We are going to query the data for 2020 because it is temporally closest to the chosen wildfire event in 2022.\n\nSource for EC-JRC’s GHS layer: Pesaresi, Martino; Politis, Panagiotis (2023): GHS-BUILT-S R2023A - GHS built-up surface grid, derived from Sentinel2 composite and Landsat, multitemporal (1975-2030). European Commission, Joint Research Centre (JRC) [Dataset] doi: 10.2905/9F06F36F-4B11-47EC-ABB0-4F8B7B1D72EA\n\nThe evalscript in this request creates a new output image where the “dataMask” band is modified based on the values in the GHS layer. If the GHS value is 0, it masks the pixel in the “dataMask” band by setting it to zero. Otherwise, it retains the original GHS value.\n\npopulation_dens = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"BUILT\", \"dataMask\"], // this sets which bands to use\n    }],\n    output: { // this defines the output image type\n      bands: 1,\n      sampleType: \"UINT8\"\n    }\n  };\n}\n \nfunction evaluatePixel(sample) {\n    let pixelMask = 1\n    \n    if (sample.BUILT == 0){\n        pixelMask = 0\n    }\n  return {\n    default: [sample.BUILT],\n    dataMask: [sample.dataMask * pixelMask]\n  };\n}\n\"\"\"\n\nrequest_data = SentinelHubRequest(\n    evalscript=population_dens,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc('0c7aa265-50f9-4947-9980-2ee5ae204803'),\n            time_interval=(\"2020-01-01\", \"2020-01-01\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi,\n    size=aoi_size,\n    config=config,\n)\n\npopulation_density = request_data.get_data()\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":29},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":30},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The GHS layer contains \n\nvalues ranging from 0 to 10,000, where higher values indicate greater population density. In this notebook, we only exclude pixels with zero values, but I would be possible to add a threshold to the script below to pinpoint areas of exceptionally high population density.\n\n# the final geotiff is a binary mask with values of 1 representing built-up pixels\nimage_data_list = population_density\n\n# Calculate pixel width and height based on image shape\npixel_width = (bottom_right_x - top_left_x) /  width \npixel_height = (top_left_y - bottom_right_y) / height\n\n# Specify the path to the directory where GeoTIFF files will be saved\noutput_directory = f\"./{folder_name}\"\n# Loop through the list of image arrays\nfor i, image_data in enumerate(image_data_list):\n    # Extract the pixel values (assuming single-band data)\n    pixel_values = image_data[:, :]\n\n    # Set values equal to zero to zero, and all other values to 1\n    pixel_values = np.where(pixel_values == 0, 0, 1)\n\n    # Specify the output path for each GeoTIFF file with the current time\n    output_path = os.path.join(output_directory, f\"output_{current_date}.tif\")\n\n    # Create a transformation for the GeoTIFF\n    transform = from_origin(top_left_x, top_left_y, pixel_width, pixel_height)\n\n    # Open a new GeoTIFF file for writing with NoData value set to NaN\n    with rasterio.open(\n        output_path,\n        'w',\n        driver='GTiff',\n        height=pixel_values.shape[0],\n        width=pixel_values.shape[1],\n        count=1,  # Only one band for pixel values\n        dtype=rasterio.float32,  # Use float32 for NaN values\n        crs='EPSG:4326',\n        transform=transform,\n        nodata=np.nan  # Set NoData value to NaN\n    ) as dst:\n        # Write the pixel values to the GeoTIFF\n        dst.write(pixel_values, 1)  # Use band 1\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":31},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":32},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file using rasterio\nwith rasterio.open(geotiff_path) as src:\n    # Read the raster data\n    raster_data = src.read(1)  # Assuming you have a single band GeoTIFF\n\n    # Get the spatial transformation information\n    transform = src.transform\n\n# Calculate the bounds based on the width and height of the raster\nleft, bottom, right, top = src.bounds\n\n# Plot the GeoTIFF data using matplotlib\nplt.figure(figsize=(8, 8))\nplt.imshow(raster_data, cmap='gray', extent=(left, right, bottom, top), origin='upper')\nplt.title('Population density in AOI')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.grid(True)\nplt.show()\n\nAll non populated areas are displayed in black in the plot while the populated areas are colored white. From this binary mask we can now create a GeoJSON file that contains only the populated areas.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":33},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":34},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The resulting GeoJSON will only contain polygons for built up areas and will be used as spatial extend to query the Sentinel-5p data later.\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file\nwith rasterio.open(geotiff_path) as src:\n    # Read the binary mask data\n    mask = src.read(1)\n\n# Convert the binary mask to vector polygons\ngeoms = list(shapes(mask, transform=src.transform, connectivity=4))  # Specify connectivity=4 for 4-connected pixels\n\n# Filter the polygons to include only those corresponding to pixels with a value of 1\nfiltered_geoms = [geom for geom, value in geoms if value == 1]\n\n# Create a GeoDataFrame from the filtered polygons\ngdf = gpd.GeoDataFrame({'geometry': [shape(geom) for geom in filtered_geoms]})\n\n# Merge all the geometries into a single MultiPolygon\nmulti_polygon = gdf.unary_union\n\n# Create a GeoDataFrame with the MultiPolygon geometry\nmulti_polygon_gdf = gpd.GeoDataFrame(geometry=[multi_polygon], crs=gdf.crs)\n\n# Specify the path to save the MultiPolygon GeoJSON file\noutput_geojson_file = f\"./{folder_name}/multi_polygon_{current_date}.geojson\"\n\n# Save the GeoDataFrame with the MultiPolygon to a GeoJSON file\nmulti_polygon_gdf.to_file(output_geojson_file, driver='GeoJSON')\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":35},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":36},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\ndisplay(GeoJSON(data=f\"./{folder_name}/multi_polygon_{current_date}.geojson\", crs=bbox_epsg))\n\nWe can see that now only the built-up areas are stored in the GeoJSON file and we can extract the coordinates from this and use them as an input for the Sentinel-5p data\n\n","type":"content","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":37},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":38},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\nwith open(f\"./{folder_name}/multi_polygon_{current_date}.geojson\") as f:\n    gj = geojson.load(f)\ndata_coordinates = gj['features'][0]['geometry']['coordinates']\n\n#print(data_coordinates)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":39},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":40},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n\nurl = \"https://creodias.sentinel-hub.com/api/v1/statistics\"\nheaders = {\n  \"Accept\": \"application/json\",\n  \"Content-Type\": \"application/json\"\n}\ndata = {\n  \"input\": {\n    \"bounds\": {\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"coordinates\": data_coordinates\n                 }\n              },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"type\": \"sentinel-5p-l2\"\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n      \"from\": \"2022-07-01T00:00:00Z\",\n      \"to\": \"2022-08-09T23:59:59Z\"\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"width\": 512,\n    \"height\": 402.581,\n    \"evalscript\": \"//VERSION=3\\nfunction setup() {\\n  return {\\n    input: [{\\n      bands: [\\\"CO\\\", \\\"dataMask\\\"], // this sets which bands to use\\n    }],\\n    output: [\\n      { id:\\\"default\\\", bands: 1, sampleType: \\\"FLOAT32\\\" },\\n      { id: \\\"dataMask\\\", bands: 1 }\\n    ]\\n  };\\n}\\n \\n\\n\\nfunction evaluatePixel(sample) {\\n  return {\\n    default: [sample.CO],\\n    dataMask: [sample.dataMask]\\n  };\\n}\"\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\nresponse = oauth.post(url, headers=headers, json=data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":41},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":42},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nresponse_data = response.json()\n#print(response_data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":43},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":44},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"content":"\n\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in response_data[\"data\"]]\nmeans = [float(entry['outputs']['default']['bands']['B0']['stats']['mean']) for entry in response_data[\"data\"]]\nstd_devs = [float(entry['outputs']['default']['bands']['B0']['stats']['stDev']) for entry in response_data[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot_date(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean CO values [mol/ m^2]\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\nplt.title('CO Values over the AOI (07/2022 - 08/2022)')\nplt.legend()\nfig.autofmt_xdate()\nplt.show()\n\nThe graph illustrates a noticeable increase in CO concentration across populated areas on July 17th, when the fire event started. Additionally, the Standard Deviation on this day and the following days is increased in comparison to the days before the fire. The highest \n\ncarbon emissions in France were recorded from June to August in 2022 which aligns well with the result of this analysis. To learn more about the carbon emissions resulting from wildfires check out this \n\nstory on the EO Dashboard that also incorporates further indicators to analyse wildfires.","type":"content","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":45},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"type":"lvl1","url":"/notebooks/inland-water-with-edc","position":0},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\"])\n\n\n\nauthor: Anca Anghelea, based on a \n\nnotebook by: William Ray\n\nSeveral lakes and other inland water bodies are featured on EO Dashboard. The datasets supporting the various geo-stories are accessible by means similar to what you will learn in this notebook.\n\nExplore EO Dashboard Stories on Oceans and Inland Water.","type":"content","url":"/notebooks/inland-water-with-edc","position":1},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":2},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"content":"In this demonstration Jupyter Notebook, we will be visualising and analysing inland water bodies using Sentinel data, demonstrating the use of EDC.\n\nWe are going to use the EDC and its associated libaries and APIs to do this. In this notebook we will learn how to:\n\nBuild a cube\n\nVisualise a variable in your data cube\n\nCreate a new variable\n\nCreate a new variable using a threshold\n\nVisualise a spatial subset of a variable over time\n\nCreate a new variable based upon space and time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":3},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#configuration","position":4},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and generate credentials automatically to access the services.\n\n# EDC libraries\nfrom edc import setup_environment_variables\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.gen2.local.combiner import CubesCombiner\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox, SentinelHubRequest, bbox_to_dimensions, DataCollection, MimeType, SHConfig, geometry\n\n# Utilities\nimport IPython.display\nfrom os import environ\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport geopandas\nimport rioxarray\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\n\n# Fetch credentials as environement variables\nsetup_environment_variables()\n\n# Pass Sentinel Hub credentials to dictionnary\nsh_credentials = dict(client_id=environ[\"SH_CLIENT_ID\"],\n                      client_secret=environ[\"SH_CLIENT_SECRET\"])\n\nDefine an AOI\n\nNext, we will define our area of interest using a bounding box. This must be provided in WGS84 coordinates to build the cube.\n\nWe have chosen an AOI covering the natural park “Valli di Comacchio” in Italy.\n\n# Define the coordinates of the bounding box\nlake_bbox = [12.09, 44.54, 12.27, 44.70]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(lake_bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/inland-water-with-edc#configuration","position":5},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":6},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"content":"Firstly, we will go through how to build a data cube.\n\nWe are going to visualise the floods using Sentinel-2 imagery. Sentinel-2 is part of the Copernicus programme and collects multispectral data globally with a revisit time of 5 days. The satellite’s multispectral imager provides collects data in 13 spectral bands spanning from the visible and near infrared to the shortwave infrared. The visible and near infrared data we will use in this example is collected at 10m resolution.\n\nCheck Sentinel-2 L2A available bands\n\nUsing EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset to help us build the cube!\n\n# Create a Sentinel Hub class, using our Sentinel Hub credentials\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\nBuild an xcube\n\nIn the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 L2A. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the B02, B03, B04, B08, CLM (Blue, Green, Red, NIR, Cloud Mask) bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from October 2016 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns2_cube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B02', 'B03', 'B04', 'B08', 'CLM'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\nOpen the xcube\n\nIn the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube. It’s important to note that at this stage, we’re not processing anything, just generating a cube on the fly with data ready to be called when needed for analysis.\n\nOnce you open the cube, you can visualise the contents. You can view the number of timestamps and a list of them all too in the Coordinates tab. You can also visualise the seperate variables, with information on the size of the variables and their data type too.\n\n# Open cube (on the fly)\ns2_cube = open_cube(s2_cube_config, **sh_credentials)\n\n# Display contents\ns2_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":7},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":8},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"content":"Now we have built our cube, let’s visualise the data! We are going to visualise a True Color image and an NDWI image in the same plot. In the below cell you can see we are selecting each band for 10:00:00 16th June 2023, and selecting the nearest acquisition to this date and time. We then stack the three bands and plot this using Matplotlib. We will call the three bands in the visible spectrum. In addition we will multiply the reflectance values by 5 to brighten the image.\n\nAnother way to visualise the extent of surface water is to use the Normalised Difference Water Index (NDWI). This is an index that can be used to extract surface water using multispectral imagery such as Sentinel-2. We can calculate the index with the Green and NIR bands as stated below, and add it into the data cube as a new variable.\n\nNDWI = Green - NIR / Green + NIR\n\nFor this we are going to create a new variable in the next cell. To create the new variable we are using two existing variables defined as s2_cube.B03 and s2_cube.B08. We then insert these variables into an index formula to create NDWI. Once ndwi has been calculated it’s attributed a long_name and units before being defined as ndwi so that we can call it as a definition later in the notebook.\n\n# Define NDWI in visualisation\nndwi = ((s2_cube.B03-s2_cube.B08)/(s2_cube.B03+s2_cube.B08))\n\nndwi.attrs['long_name']='NDWI'\nndwi.attrs['units']='unitless'\n\ns2_cube['NDWI']= ndwi  \n\nNext we want to plot both the True Color image and the NDWI in the same plot. We will use Matplotlib to achieve this.\n\n# Select the bands and stack them.\nRed = s2_cube.B04.sel(time='2023-06-17 10:00:00', method='nearest')\nGreen = s2_cube.B03.sel(time='2023-06-17 10:00:00', method='nearest')\nBlue = s2_cube.B02.sel(time='2023-06-17 10:00:00', method='nearest')\n\nrgb = np.dstack((Red,Green,Blue)) #Stack the three arrays\n\nndwi = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[10, 15])\nf.add_subplot(1, 2, 1)\nplt.title(f\"True Color: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(5 * rgb)  # We multiply the rgb by 5 to make the image brighter\nf.add_subplot(1, 2, 2)\nplt.title(f\"NDWI: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(ndwi, vmin=-1, vmax=1, cmap='GnBu')\nplt.show()\n\nThis looks good, and the extent of the flood waters is visualised really nicely here. The 10m resolution also enables us to see individual fields around the lake with the linear boundaries of the fields highlighted nicely in the high resolution image provided by the 10m Sentinel 2 bands.\n\nLet’s try and visualise some more dates in the time period that we are examining;\n\n# Select timestamps\nndwi1 = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\nndwi2 = s2_cube.NDWI.sel(time='2023-06-24 10:00:00', method='nearest')\nndwi3 = s2_cube.NDWI.sel(time='2023-06-29 10:00:00', method='nearest')\nndwi4 = s2_cube.NDWI.sel(time='2023-07-04 10:00:00', method='nearest')\nndwi5 = s2_cube.NDWI.sel(time='2023-07-07 10:00:00', method='nearest')\nndwi6 = s2_cube.NDWI.sel(time='2023-07-09 10:00:00', method='nearest')\n\n\n# Plot \nf = plt.figure(figsize=[15,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = ndwi1.plot.imshow(ax=ax1, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi2.plot.imshow(ax=ax2, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi3.plot.imshow(ax=ax3, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi4.plot.imshow(ax=ax4, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi5.plot.imshow(ax=ax5, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi6.plot.imshow(ax=ax6, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"NDWI\")\n\n#we will save the output image so we need to ensure that it is fully rendered \nplt.tight_layout() \n\n# Save the figure to a PNG file\nplt.savefig('NDWI.png')\n\nplt.show()\n\nWe could use the NDWI to estimate the surface water extent. The more images we have available, the more reliable the estimate can be. Examining the satellite images above we observe that not all of the images would be useful, as some of the lake area is covered with clouds. To overcome this limitation and have a denser time series we could rely on synthetic aperture radar observations, for example from the Copernicus Sentinel-1 platform.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":9},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":10},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"content":"Like Sentinel-2, Sentinel-1 is also part of the Copernicus programme and collects data globally with a revisit time of 5 days. In contrast to Sentinel-2, Sentinel-1 SAR is an active sensor using SAR signals recording the backscatter. Due to the wavelengths used, SAR is not hindered by clouds and can be operated day and night.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":11},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":12},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":13},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":14},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call just the VV polarisation band.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns1_cube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VV'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":15},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":16},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ns1_cube = open_cube(s1_cube_config, **sh_credentials)\n\n# Display contents\ns1_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":17},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":18},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"content":"We are going to use the VV band to visualise the flooding. From our earlier visualisation, we know that the area had some cloud coverage around the date 2023-07-04. We will search for Sentinel-1 acquisitions around that date in order to obtain a denser time series.\n\nRadar data has very large dynamic range a very imbalanced histogram (>95% of all values are smaller than 1, but the remaining 5 % can be impractically large). Thus, to obtain a visualisation with a better contrast in which the water bodies would be darker and the land pixels would be brighter, it is recommended to convert the data to log-scale.\nTo convert the pixel values from Digital Number to decibels we can mutiply the log10 of each DN pixel by 10. Secondly, as there will be pixels with a value of -inf after this operation, we need to account for this with the second function which will automatically assign 0 to these pixels.\n\n# Convert VV Digital numbers to Decibels\nvv_dn = s1_cube.VV\nvv_db = 10 * (np.log10(vv_dn))\n\nvv_db = vv_db.where(np.isfinite(vv_db), 0)\n\nvv_db.attrs['long_name']='VV_dB'\nvv_db.attrs['units']='decibels'\n\ns1_cube['VV_dB']= vv_db\n\nLike previously, we are going to visualise the VV_dB variable we have just generated for our AOI.\n\n# select and define the timestamp you want to visualise \nVV_dB_timestamp = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\n\n# plot the timestamp\nVV_dB_timestamp.plot.imshow(vmin=-40, vmax=0, cmap='winter', figsize=(10, 10))\n\n# save and display the plot\nplt.show()\n\nThis looks very similar to the NDWI we derived earlier showing the water extent fairly clearly (the blue areas). Let’s visualise it over several timestamps to confirm that this is a good variable to use to generate a lake mask.\n\n#### Timestamp selection\nvv1 = s1_cube.VV_dB.sel(time='2023-06-03 10:00:00', method='nearest')\nvv2 = s1_cube.VV_dB.sel(time='2023-06-04 10:00:00', method='nearest')\nvv3 = s1_cube.VV_dB.sel(time='2023-06-15 10:00:00', method='nearest')\nvv4 = s1_cube.VV_dB.sel(time='2023-06-27 10:00:00', method='nearest')\nvv5 = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\nvv6 = s1_cube.VV_dB.sel(time='2023-07-10 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = vv1.plot.imshow(ax=ax1, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv2.plot.imshow(ax=ax2, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv3.plot.imshow(ax=ax3, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv4.plot.imshow(ax=ax4, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv5.plot.imshow(ax=ax5, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv6.plot.imshow(ax=ax6, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"VV dB\")\n\nplt.show()\n\nDepending on the local conditions (e.g. terrain orientation, slope) and weather conditions, optical or radar imagery may be more useful. In this case both types of observations seem to provide a good view of the water surface area extent.\n\nNext we will generate a flood mask using a threshold.\n\nfor SAR images, generally, as a good rule of thumb, in the VV band, values below -20 dB are usually surface water. We will try this value first, but we will also look to visualise how the flood mask changes if we adjust the threshold value.\n\nobserving the NDWI range of values, we can chose values above 0.25 to correspond to the water class.\n\nFirst, let’s generate the new variable using the .where function in xarray.\n\nAt first glance, the below cell may not make much sense. It may read that the step 1 function as assigning a value of 1 to pixels in VV_dB that are equal or more than -20. However, what is actually happening is that the .where function preserves all the pixel values in the variable that are below -20 and assigns everything else a value of 1. More can be found in the xarray documentation \n\nhttp://​xarray​.pydata​.org​/en​/stable​/generated​/xarray​.DataArray​.where​.html\n\n# mask the Sentinel-1 data\n\n# Assign all pixels equal or smaller than -20 a value of 1 and preserve the values of all other pixels \nstep1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns1_cube['water'] = water\n\nNext let’s see what happens to the mask extent if we change the threshold to -15 dB and -25dB:\n\n# Sentinel-1\nwater_threshold1_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -15, 1)\nwater_threshold2_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\nwater_threshold3_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -25, 1)\n\nwater_threshold1_step2 = water_threshold1_step1.where(water_threshold1_step1 == 1, 0)\nwater_threshold2_step2 = water_threshold2_step1.where(water_threshold2_step1 == 1, 0)\nwater_threshold3_step2 = water_threshold3_step1.where(water_threshold3_step1 == 1, 0)\n\nwater_threshold1 = water_threshold1_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold2 = water_threshold2_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold3 = water_threshold3_step2.sel(time='2023-06-15 10:00:00', method='nearest')\n\nNext we will plot the new thresholds we want to test:\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\n# mask the Sentinel-2 data\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of pixels \nstep11 = ndwi1.where(ndwi1 < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater1 = step1.where(step1 == 1, 0)\n\nwater1.attrs['long_name'] ='water'\nwater1.attrs['units'] ='nounits'\n\ns2_cube['water'] = water1\n\n# Sentinel-2\nwater_threshold1_step11 = ndwi1.where(ndwi1 < 0.15, 1)\nwater_threshold2_step11 = ndwi1.where(ndwi1 < 0.25, 1)\nwater_threshold3_step11 = ndwi1.where(ndwi1 < 0.30, 1)\n\nwater_threshold1_step21 = water_threshold1_step11.where(water_threshold1_step11 == 1, 0)\nwater_threshold2_step21 = water_threshold2_step11.where(water_threshold2_step11 == 1, 0)\nwater_threshold3_step21 = water_threshold3_step11.where(water_threshold3_step11 == 1, 0)\n\nwater_threshold11 = water_threshold1_step21\nwater_threshold21 = water_threshold2_step21\nwater_threshold31 = water_threshold3_step21\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold11.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold21.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold31.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nObserve the differences in the water mask due to the threshold.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":19},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":20},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"content":"Let’s estimate the area covered by water during the time period we are examining.\n\nWe can also estimate which is the area that is most covered by water by dividing the sum of the water pixels by the number of timesteps in the data cube (the count).\n\n# previously we only kept 1 time step when we selected ndwi1\n# now we want to keep the full datacube in order to average in time\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of all other pixels \nstep1 = s2_cube.NDWI.where(s2_cube.NDWI < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns2_cube['water'] = water\n\n\nwater_sum = s2_cube.NDWI.sum(dim=\"time\")\nwater_count = s2_cube.NDWI.count(dim=\"time\")\nwater_average = water_sum / water_count\n\n\nwater_average.attrs['long_name']='water area'\nwater_average.attrs['units']='nounits'\n\nndwi['water_average']= water_average\n\nNow let’s plot the water_average into a plot:\n\nwater_average.plot.imshow(cmap='GnBu', vmin=0, vmax=0.5, figsize=(10, 10))\n\nplt.tight_layout()\n\n#expport to png\nplt.savefig('figure.png')\n\nplt.show()\n\nThis looks great, we have identified the lake area very clearly here and can also observe how the lake may change in size over time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":21},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":22},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"content":"This \n\nNotebook demonstrates how to:\n\nrequest data from selected Copernicus Services,\nrequest data from Copernicus Climate Data Store,\nrequest data from ESA Climate Change Initiative.","type":"content","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":23}]}